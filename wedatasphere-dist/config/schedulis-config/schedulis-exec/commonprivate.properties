## hadoop security manager setting common to all hadoop jobs
hadoop.security.manager.class=azkaban.security.HadoopSecurityManager_H_2_0

## hadoop security related settings

# proxy.keytab.location=
# proxy.user=

azkaban.should.proxy=false
obtain.binary.token=false
# obtain.namenode.token=true
# obtain.jobtracker.token=true

# global jvm args for all jobs. e.g. java.io.temp.dir, java.library.path
#jobtype.global.jvm.args=-Xms50m -Xmx60m

# hadoop
hadoop.home=/opt/cloudera/parcels/CDH/lib/hadoop
hadoop.conf.dir=/etc/hadoop/conf
hive.home=/opt/cloudera/parcels/CDH/lib/hive
spark.home=/wedatasphere/install/spark-2.4.3-bin-hadoop2.6
schedulis.home=/wedatasphere/install/schedulis/schedulis_0.7.1_exec
jobtypes.home=${schedulis.home}/plugins/jobtypes
# configs for jobtype security settings
execute.as.user=true
azkaban.native.lib=/wedatasphere/install/schedulis/schedulis_0.7.1_exec/lib
bdp.client.conf.file=/wedatasphere/install/schedulis/schedulis_0.7.1_exec/conf/bdp-job-client.properties

# global classpath items for all jobs. e.g. hadoop-core jar, hadoop conf
#jobtype.global.classpath=${hadoop.home}/share/hadoop/common/*,${hadoop.home}/share/hadoop/common/lib/*,${hadoop.home}/share/hadoop/hdfs/*,${hadoop.home}/share/hadoop/hdfs/lib/*,${hadoop.home}/share/hadoop/mapreduce/*,${hadoop.home}/share/hadoop/mapreduce/lib/*,${hadoop.home}/share/hadoop/yarn/*,${hadoop.home}/share/hadoop/yarn/lib/*,${hive.home}/lib/*,/appcom/config/hadoop-config,/appcom/config/hive-config
